{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3Zsa50vycAoa",
      "metadata": {
        "id": "3Zsa50vycAoa"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import transformers\n",
        "import torch\n",
        "# sys.path.append(\"./Incontext-learning\") # this part works for goole colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "CM2tO10Z552-",
      "metadata": {
        "id": "CM2tO10Z552-"
      },
      "outputs": [],
      "source": [
        "import utility\n",
        "import metric\n",
        "import importlib\n",
        "importlib.reload(utility)\n",
        "importlib.reload(metric)\n",
        "from utility import (data_selection, evaluate_zeroshot,evaluate_finetuning,evaluate_demonstrations as  evaluate_fewshots, finetune_model_eval, extract_attentionweights, extract_raw_attention_scores_simple)\n",
        "from metric import Rec2FTP, SimAOU\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "937daa06",
      "metadata": {
        "id": "937daa06"
      },
      "outputs": [],
      "source": [
        "from transformers.models.qwen3 import modeling_qwen3\n",
        "from customized_Qwen import Qwen3Attention_v1\n",
        "modeling_qwen3.Qwen3Attention = Qwen3Attention_v1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88f461b",
      "metadata": {
        "id": "d88f461b"
      },
      "source": [
        "# check point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ddf39116",
      "metadata": {
        "id": "ddf39116"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load SST-2 dataset\n",
        "# dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "# load SST-5 dataset\n",
        "dataset = load_dataset(\"SetFit/sst5\")\n",
        "\n",
        "# Load Qwen3 tokenizer and model\n",
        "model_name = \"Qwen/Qwen3-0.6B\"\n",
        "model_path = \"/home/students/wli/UniHeidelberg/semster2/final_projects/models/Qwen3-0.6B-Base\"\n",
        "# model_path = model_name\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, device_map = \"auto\")\n",
        "\n",
        "tokenizer.padding_side = \"left\"\n",
        "# Make sure tokenizer has pad token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# if getattr(model.config.pad_token_id, None) is None:\n",
        "    # pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8c49cee8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import Qwne3ForCausalLM\n",
        "from transformers import Qwen3ForCausalLM\n",
        "model = Qwen3ForCausalLM.from_pretrained(model_path, device_map = \"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d3feb60f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen3ForCausalLM(\n",
              "  (model): Qwen3Model(\n",
              "    (embed_tokens): Embedding(151936, 1024)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention_v1(\n",
              "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
              "    (rotary_emb): Qwen3RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d659a25c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 8544\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 1101\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 2210\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9b2a1508",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 28 layers in model.model.layers\n",
            "Registering hook on layer 0: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 1: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 2: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 3: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 4: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 5: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 6: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 7: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 8: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 9: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 10: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 11: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 12: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 13: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 14: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 15: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 16: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 17: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 18: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 19: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 20: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 21: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 22: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 23: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 24: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 25: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 26: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Registering hook on layer 27: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 0 with 2 samples\n",
            "Layer 0: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 0: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 0: No valid input found\n",
            "Layer 1: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 1: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 1: No valid input found\n",
            "Layer 2: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 2: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 2: No valid input found\n",
            "Layer 3: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 3: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 3: No valid input found\n",
            "Layer 4: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 4: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 4: No valid input found\n",
            "Layer 5: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 5: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 5: No valid input found\n",
            "Layer 6: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 6: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 6: No valid input found\n",
            "Layer 7: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 7: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 7: No valid input found\n",
            "Layer 8: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 8: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 8: No valid input found\n",
            "Layer 9: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 9: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 9: No valid input found\n",
            "Layer 10: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 10: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 10: No valid input found\n",
            "Layer 11: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 11: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 11: No valid input found\n",
            "Layer 12: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 12: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 12: No valid input found\n",
            "Layer 13: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 13: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 13: No valid input found\n",
            "Layer 14: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 14: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 14: No valid input found\n",
            "Layer 15: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 15: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 15: No valid input found\n",
            "Layer 16: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 16: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 16: No valid input found\n",
            "Layer 17: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 17: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 17: No valid input found\n",
            "Layer 18: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 18: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 18: No valid input found\n",
            "Layer 19: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 19: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 19: No valid input found\n",
            "Layer 20: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 20: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 20: No valid input found\n",
            "Layer 21: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 21: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 21: No valid input found\n",
            "Layer 22: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 22: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 22: No valid input found\n",
            "Layer 23: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 23: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 23: No valid input found\n",
            "Layer 24: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 24: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 24: No valid input found\n",
            "Layer 25: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 25: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 25: No valid input found\n",
            "Layer 26: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 26: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 26: No valid input found\n",
            "Layer 27: Module type: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
            "Layer 27: Input type: <class 'tuple'>, Input length: 0\n",
            "Layer 27: No valid input found\n",
            "Captured attention scores for layers: []\n",
            "Warning: No attention scores captured for layer 0\n",
            "Warning: No attention scores captured for layer 1\n",
            "Warning: No attention scores captured for layer 2\n",
            "Warning: No attention scores captured for layer 3\n",
            "Warning: No attention scores captured for layer 4\n",
            "Warning: No attention scores captured for layer 5\n",
            "Warning: No attention scores captured for layer 6\n",
            "Warning: No attention scores captured for layer 7\n",
            "Warning: No attention scores captured for layer 8\n",
            "Warning: No attention scores captured for layer 9\n",
            "Warning: No attention scores captured for layer 10\n",
            "Warning: No attention scores captured for layer 11\n",
            "Warning: No attention scores captured for layer 12\n",
            "Warning: No attention scores captured for layer 13\n",
            "Warning: No attention scores captured for layer 14\n",
            "Warning: No attention scores captured for layer 15\n",
            "Warning: No attention scores captured for layer 16\n",
            "Warning: No attention scores captured for layer 17\n",
            "Warning: No attention scores captured for layer 18\n",
            "Warning: No attention scores captured for layer 19\n",
            "Warning: No attention scores captured for layer 20\n",
            "Warning: No attention scores captured for layer 21\n",
            "Warning: No attention scores captured for layer 22\n",
            "Warning: No attention scores captured for layer 23\n",
            "Warning: No attention scores captured for layer 24\n",
            "Warning: No attention scores captured for layer 25\n",
            "Warning: No attention scores captured for layer 26\n",
            "Warning: No attention scores captured for layer 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [02:52<00:00, 172.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All hooks removed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "output = extract_attentionweights(\n",
        "    model, tokenizer, [\"This is a test sentence.\",\" Another test sentence. label: \"], \n",
        "    batch_size=2, before_softmax=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e0e55228",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [01:06<?, ?it/s]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m output = \u001b[43mextract_raw_attention_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThis is a test sentence.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m Another test sentence. label: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/utility.py:487\u001b[39m, in \u001b[36mextract_raw_attention_scores\u001b[39m\u001b[34m(model, tokenizer, test_data, batch_size)\u001b[39m\n\u001b[32m    484\u001b[39m qkv_cache.clear()\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# Forward pass triggers hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[38;5;66;03m# Extract raw scores for last token\u001b[39;00m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model.config.num_hidden_layers):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:940\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    939\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    942\u001b[39m     output = output.to_tuple()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:480\u001b[39m, in \u001b[36mQwen3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    456\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    457\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    458\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[33;03m    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03m        Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    478\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    492\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001b[32m   1062\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[32m   1066\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:410\u001b[39m, in \u001b[36mQwen3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    407\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    423\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    424\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    425\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:260\u001b[39m, in \u001b[36mQwen3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    258\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1806\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1804\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[32m   1805\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1806\u001b[39m     hook_result = \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1809\u001b[39m     result = hook_result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/utility.py:476\u001b[39m, in \u001b[36mextract_raw_attention_scores.<locals>.<lambda>\u001b[39m\u001b[34m(module, input, output, idx)\u001b[39m\n\u001b[32m    473\u001b[39m     hooks.append(hook)\n\u001b[32m    474\u001b[39m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[33m'\u001b[39m\u001b[33mself_attn\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    475\u001b[39m     hook = layer.self_attn.register_forward_hook(\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m       \u001b[38;5;28;01mlambda\u001b[39;00m module, \u001b[38;5;28minput\u001b[39m, output, idx=layer_idx: \u001b[43mqkv_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    477\u001b[39m     )\n\u001b[32m    478\u001b[39m     hooks.append(hook)\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_data), batch_size), leave=\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/utility.py:447\u001b[39m, in \u001b[36mextract_raw_attention_scores.<locals>.qkv_hook\u001b[39m\u001b[34m(module, input, output, layer_idx)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;66;03m# This depends on the model architecture\u001b[39;00m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# For most transformers, we can get Q, K, V from the attention module\u001b[39;00m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m'\u001b[39m\u001b[33mq_proj\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m'\u001b[39m\u001b[33mk_proj\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    446\u001b[39m   \u001b[38;5;66;03m# Get the input to attention (hidden states)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m   hidden_states = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[32m    449\u001b[39m   \u001b[38;5;66;03m# Compute Q, K, V\u001b[39;00m\n\u001b[32m    450\u001b[39m   q = module.q_proj(hidden_states)\n",
            "\u001b[31mIndexError\u001b[39m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "output = extract_raw_attention_scores(\n",
        "    model, tokenizer, [\"This is a test sentence.\",\" Another test sentence. label: \"], \n",
        "    batch_size=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a3a6126b",
      "metadata": {
        "id": "a3a6126b"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"] # the orginal paper use this\n",
        "test_dataset = dataset[\"validation\"]\n",
        "\n",
        "def add_idx(example, idx):\n",
        "    example[\"idx\"] = idx\n",
        "    return example\n",
        "\n",
        "test_dataset = test_dataset.map(add_idx, with_indices=True)\n",
        "# Format examples as causal LM inputs\n",
        "def preprocess_function(examples):\n",
        "    label_map = {0: \"negative\", 1: \"positive\"}\n",
        "    inputs = [\n",
        "        f\"Sentence: {sentence} Label: {label_map[label]}\"\n",
        "        for sentence, label in zip(examples[\"sentence\"], examples[\"label\"])\n",
        "    ]\n",
        "    # Tokenize with padding/truncation\n",
        "    tokenized = tokenizer(\n",
        "        inputs,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=256,\n",
        "        # return_tensors=\"pt\"\n",
        "        return_tensors=None\n",
        "    )\n",
        "    # Set labels equal to input_ids for causal LM loss\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "def preprocess_function_sst5(examples):\n",
        "    label_map = {0: \"terrible\", 1: \"bad\", 2: \"neutral\", 3: \"good\", 4: \"very great\"}\n",
        "    inputs = [\n",
        "        f\"Sentence: {sentence} Label: {label_map[label]}\"\n",
        "        for sentence, label in zip(examples[\"text\"], examples[\"label\"])\n",
        "    ]\n",
        "    # Tokenize with padding/truncation\n",
        "    tokenized = tokenizer(\n",
        "        inputs,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=256,\n",
        "        # return_tensors=\"pt\"\n",
        "        return_tensors=None\n",
        "    )\n",
        "    # Set labels equal to input_ids for causal LM loss\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "# Tokenize the dataset\n",
        "# tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "train_tokenized_datasets = train_dataset.map(preprocess_function_sst5, batched = True, remove_columns = train_dataset.column_names)\n",
        "test_tokenized_datasets = test_dataset.map(preprocess_function_sst5, batched=True, remove_columns=test_dataset.column_names)\n",
        "# Data collator (handles padding dynamically in batch)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "VfOgObQEcX31",
      "metadata": {
        "id": "VfOgObQEcX31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "customized attention layer 0 is called\n",
            "customized attention layer 1 is called\n",
            "customized attention layer 2 is called\n",
            "customized attention layer 3 is called\n",
            "customized attention layer 4 is called\n",
            "customized attention layer 5 is called\n",
            "customized attention layer 6 is called\n",
            "customized attention layer 7 is called\n",
            "customized attention layer 8 is called\n",
            "customized attention layer 9 is called\n",
            "customized attention layer 10 is called\n",
            "customized attention layer 11 is called\n",
            "customized attention layer 12 is called\n",
            "customized attention layer 13 is called\n",
            "customized attention layer 14 is called\n",
            "customized attention layer 15 is called\n",
            "customized attention layer 16 is called\n",
            "customized attention layer 17 is called\n",
            "customized attention layer 18 is called\n",
            "customized attention layer 19 is called\n",
            "customized attention layer 20 is called\n",
            "customized attention layer 21 is called\n",
            "customized attention layer 22 is called\n",
            "customized attention layer 23 is called\n",
            "customized attention layer 24 is called\n",
            "customized attention layer 25 is called\n",
            "customized attention layer 26 is called\n",
            "customized attention layer 27 is called\n",
            "Sentence: a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films. Label: \"Theatrical\".\n",
            "\n",
            "What structured data could we\n"
          ]
        }
      ],
      "source": [
        "# test the behavior of LLM before fine tuing\n",
        "prompt = \"Sentence: a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films. Label:\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "# You can control max_length or early stopping\n",
        "output_ids = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=10,    # adjust based on expected label length\n",
        "    do_sample=False,       # greedy decoding\n",
        "    pad_token_id=tokenizer.pad_token_id\n",
        ")\n",
        "\n",
        "# Decode generated tokens\n",
        "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9f0f4688",
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_dataset = test_dataset.select(range(32)) # use a smaller test set for debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b78a38d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': [\"although there are several truly jolting scares , there 's also an abundance of hackneyed dialogue and more silly satanic business than you can shake a severed limb at .\", \"it believes it 's revealing some great human truths , when , in reality , it 's churning ground that has long passed the point of being fertile .\"], 'label': tensor([2, 2]), 'label_text': ['neutral', 'neutral'], 'idx': tensor([836, 911])}\n",
            "<class 'dict'>\n"
          ]
        }
      ],
      "source": [
        "for batch in DataLoader(test_dataset, batch_size=2, shuffle=True):\n",
        "    print(batch)\n",
        "    print(type(batch))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f651e2a7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1ce1a8d3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/138 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 2303.54 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 1/138 [00:09<21:39,  9.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 2333.88 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 2/138 [00:18<20:37,  9.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 3199.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 3/138 [00:27<20:38,  9.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 3199.54 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 4/138 [00:36<20:22,  9.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 4070.29 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 5/138 [00:45<20:24,  9.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 4915.75 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 6/138 [00:55<20:20,  9.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 4915.76 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 7/138 [01:04<20:07,  9.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.20 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 8/138 [01:13<20:03,  9.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.21 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 9/138 [01:22<19:38,  9.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.30 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 10/138 [01:31<19:27,  9.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 11/138 [01:40<19:09,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 12/138 [01:49<18:49,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 13/138 [01:58<18:42,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 14/138 [02:07<18:24,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 15/138 [02:15<18:09,  8.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.44 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 16/138 [02:25<18:12,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5791.44 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 17/138 [02:33<17:56,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 5821.29 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 18/138 [02:42<17:55,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 6667.59 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 19/138 [02:52<18:00,  9.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7516.15 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 20/138 [03:01<18:01,  9.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7516.46 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 21/138 [03:10<17:47,  9.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7516.47 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 22/138 [03:19<17:35,  9.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7516.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 23/138 [03:28<17:30,  9.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.08 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 24/138 [03:38<17:25,  9.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.08 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 25/138 [03:47<17:05,  9.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.08 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 26/138 [03:55<16:46,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.08 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 27/138 [04:04<16:30,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.08 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 28/138 [04:13<16:18,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.09 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 29/138 [04:22<16:07,  8.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.09 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 30/138 [04:31<16:04,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.10 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 31/138 [04:40<15:59,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.10 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 32/138 [04:49<15:55,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.10 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 33/138 [04:58<15:39,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 7577.10 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 34/138 [05:07<15:24,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8029.94 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 35/138 [05:16<15:21,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8030.00 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 36/138 [05:25<15:12,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8030.02 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 37/138 [05:33<15:01,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8030.09 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 38/138 [05:43<15:00,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8030.12 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 39/138 [05:52<14:46,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8090.91 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 40/138 [06:00<14:35,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8090.94 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 41/138 [06:09<14:24,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8120.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 42/138 [06:18<14:19,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8363.53 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 43/138 [06:27<14:10,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8363.90 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 44/138 [06:36<14:05,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8364.03 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 45/138 [06:45<13:55,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8364.03 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 46/138 [06:54<13:43,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8364.03 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 47/138 [07:03<13:37,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8364.03 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 48/138 [07:12<13:26,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8364.03 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 49/138 [07:21<13:12,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8364.04 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 50/138 [07:30<13:02,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8364.05 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 51/138 [07:39<12:51,  8.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8364.07 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 52/138 [07:48<12:45,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8424.50 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 53/138 [07:56<12:36,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8575.42 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 54/138 [08:05<12:28,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8786.86 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 55/138 [08:14<12:22,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8787.14 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 56/138 [08:23<12:14,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8787.15 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 57/138 [08:32<12:00,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 8787.16 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 58/138 [08:41<11:50,  8.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9001.00 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 59/138 [08:50<11:47,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9001.00 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 60/138 [08:59<11:34,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9001.12 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 61/138 [09:08<11:25,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9001.12 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 62/138 [09:17<11:14,  8.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9001.12 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 63/138 [09:25<11:03,  8.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9001.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▋     | 64/138 [09:34<10:53,  8.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9001.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 65/138 [09:43<10:44,  8.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9001.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 66/138 [09:52<10:41,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9001.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▊     | 67/138 [10:01<10:32,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9152.25 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 68/138 [10:10<10:24,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9152.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 69/138 [10:19<10:13,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9152.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 70/138 [10:28<10:09,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9152.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████▏    | 71/138 [10:37<09:56,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9152.45 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 72/138 [10:46<09:47,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9152.57 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 73/138 [10:55<09:38,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9152.57 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 74/138 [11:03<09:27,  8.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9273.18 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 75/138 [11:12<09:20,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9457.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 76/138 [11:21<09:15,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9457.50 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 77/138 [11:30<09:03,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9670.52 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 78/138 [11:39<08:56,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9670.92 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 79/138 [11:48<08:45,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9823.61 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 80/138 [11:57<08:39,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9823.62 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▊    | 81/138 [12:06<08:27,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9823.62 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 82/138 [12:15<08:17,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9823.62 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 83/138 [12:24<08:09,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9823.62 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 84/138 [12:32<07:58,  8.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9823.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 85/138 [12:41<07:48,  8.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9823.82 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 86/138 [12:50<07:40,  8.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9915.54 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 87/138 [12:59<07:33,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9916.11 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 88/138 [13:08<07:23,  8.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9916.54 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 89/138 [13:17<07:13,  8.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9916.88 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 90/138 [13:26<07:06,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 9917.79 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 91/138 [13:35<07:00,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10039.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 92/138 [13:44<06:51,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10040.38 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 93/138 [13:53<06:44,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10041.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 94/138 [14:02<06:33,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10041.67 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 95/138 [14:10<06:22,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10041.68 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 96/138 [14:19<06:12,  8.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10041.79 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 97/138 [14:28<06:05,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10042.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 98/138 [14:37<05:57,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10073.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 99/138 [14:46<05:47,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10073.77 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 100/138 [14:55<05:39,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10254.70 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 101/138 [15:04<05:30,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10346.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 102/138 [15:13<05:21,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10346.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 103/138 [15:22<05:13,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10377.53 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 104/138 [15:31<05:03,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10378.30 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 105/138 [15:40<04:53,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10378.76 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 106/138 [15:49<04:46,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10501.38 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 107/138 [15:58<04:37,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10502.14 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 108/138 [16:06<04:27,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10504.24 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 109/138 [16:15<04:17,  8.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10504.82 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 110/138 [16:24<04:08,  8.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10504.96 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 111/138 [16:33<04:00,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10627.07 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 112/138 [16:42<03:52,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10627.54 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 113/138 [16:51<03:43,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10627.55 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 114/138 [17:00<03:34,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10657.99 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 115/138 [17:09<03:24,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10658.73 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 116/138 [17:18<03:15,  8.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10659.68 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 117/138 [17:26<03:06,  8.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10660.25 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 118/138 [17:35<02:57,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10660.62 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 119/138 [17:44<02:48,  8.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10661.65 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 120/138 [17:53<02:40,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10722.90 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 121/138 [18:02<02:31,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10723.69 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 122/138 [18:11<02:22,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10814.65 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 123/138 [18:20<02:13,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10845.77 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 124/138 [18:29<02:04,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10846.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 125/138 [18:38<01:56,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10846.62 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 126/138 [18:47<01:47,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10847.76 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 127/138 [18:56<01:38,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10909.19 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 128/138 [19:05<01:29,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10909.64 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 129/138 [19:14<01:20,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10940.52 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 130/138 [19:23<01:11,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10971.36 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 131/138 [19:31<01:02,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10972.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 132/138 [19:40<00:53,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10973.65 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 133/138 [19:49<00:44,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10973.77 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 134/138 [19:58<00:35,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10973.84 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 135/138 [20:07<00:26,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 10973.91 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▊| 136/138 [20:16<00:17,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11096.56 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 137/138 [20:25<00:08,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11096.99 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 138/138 [20:31<00:00,  8.92s/it]\n",
            "  1%|▏         | 1/69 [00:01<01:08,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11177.70 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 2/69 [00:01<01:00,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11179.93 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 3/69 [00:02<01:05,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11264.33 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 4/69 [00:04<01:06,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11355.07 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 5/69 [00:04<01:01,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11355.14 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 6/69 [00:05<01:00,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11355.14 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 7/69 [00:06<00:56,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11355.14 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 8/69 [00:07<00:54,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11355.14 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 9/69 [00:08<00:54,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11355.14 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 10/69 [00:09<00:57,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11422.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 11/69 [00:10<00:55,  1.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11422.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 12/69 [00:11<00:56,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11422.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 13/69 [00:12<00:52,  1.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11422.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 14/69 [00:13<00:50,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11422.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 15/69 [00:14<00:50,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11422.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 16/69 [00:15<00:50,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11422.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 17/69 [00:16<00:49,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11422.66 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 18/69 [00:17<00:50,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11434.75 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 19/69 [00:18<00:49,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11434.91 MB\n",
            "RAM usage: 11530.89 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 21/69 [00:20<00:48,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11530.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 22/69 [00:21<00:47,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11530.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 23/69 [00:22<00:46,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11530.99 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 24/69 [00:23<00:42,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11530.99 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 25/69 [00:23<00:40,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11533.38 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 26/69 [00:24<00:40,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11533.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 27/69 [00:25<00:40,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11533.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 28/69 [00:26<00:39,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11533.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 29/69 [00:27<00:37,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11533.43 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 30/69 [00:29<00:39,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.93 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 31/69 [00:30<00:39,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.94 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▋     | 32/69 [00:31<00:37,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.94 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 33/69 [00:31<00:34,  1.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.94 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 34/69 [00:32<00:33,  1.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.94 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 35/69 [00:33<00:31,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.94 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 36/69 [00:34<00:31,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.94 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 37/69 [00:35<00:29,  1.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.94 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 38/69 [00:36<00:31,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 39/69 [00:37<00:30,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 40/69 [00:39<00:31,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 41/69 [00:40<00:30,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 42/69 [00:41<00:28,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 43/69 [00:42<00:27,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 44/69 [00:43<00:26,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 45/69 [00:44<00:24,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11576.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 46/69 [00:45<00:23,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 47/69 [00:46<00:21,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 48/69 [00:46<00:20,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 49/69 [00:47<00:18,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 50/69 [00:48<00:18,  1.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 51/69 [00:49<00:17,  1.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 52/69 [00:51<00:17,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 53/69 [00:51<00:15,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.26 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 54/69 [00:53<00:15,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 55/69 [00:54<00:14,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.27 MB\n",
            "RAM usage: 11577.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 57/69 [00:56<00:12,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 58/69 [00:57<00:11,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.27 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 59/69 [00:58<00:09,  1.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.27 MB\n",
            "RAM usage: 11577.29 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 61/69 [01:00<00:08,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.29 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 62/69 [01:01<00:07,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.30 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 63/69 [01:02<00:05,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.30 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 64/69 [01:03<00:05,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.30 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 65/69 [01:04<00:04,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.30 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 66/69 [01:05<00:03,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.30 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 67/69 [01:06<00:01,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.30 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▊| 68/69 [01:07<00:00,  1.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11577.30 MB\n",
            "RAM usage: 11577.38 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69/69 [01:08<00:00,  1.01it/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4952ab5be0634191ab0c48b2cb4645fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1101 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:04, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training finished!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/138 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11611.91 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 2/138 [00:01<01:32,  1.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11643.12 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 3/138 [00:01<01:23,  1.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11643.12 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 4/138 [00:02<01:18,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11647.25 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 5/138 [00:03<01:17,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 6/138 [00:03<01:22,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 7/138 [00:04<01:19,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 8/138 [00:05<01:22,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.95 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 9/138 [00:05<01:14,  1.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 10/138 [00:06<01:12,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 11/138 [00:06<01:13,  1.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 12/138 [00:07<01:11,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 13/138 [00:07<01:10,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 14/138 [00:08<01:08,  1.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 15/138 [00:08<01:07,  1.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 16/138 [00:09<01:07,  1.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 17/138 [00:09<01:06,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 18/138 [00:10<01:06,  1.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 19/138 [00:11<01:10,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 20/138 [00:11<01:13,  1.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 21/138 [00:12<01:09,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 22/138 [00:12<01:08,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 23/138 [00:13<01:10,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 24/138 [00:14<01:11,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 25/138 [00:14<01:08,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 26/138 [00:15<01:05,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 27/138 [00:15<01:03,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 28/138 [00:16<01:02,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 29/138 [00:17<01:02,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 30/138 [00:17<01:00,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.97 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 31/138 [00:18<01:00,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 32/138 [00:18<01:00,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 33/138 [00:19<00:59,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 34/138 [00:19<00:58,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 35/138 [00:20<01:01,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 36/138 [00:21<00:59,  1.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 37/138 [00:21<00:58,  1.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 38/138 [00:22<00:57,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 39/138 [00:22<00:57,  1.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 40/138 [00:23<00:59,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 41/138 [00:24<00:57,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 42/138 [00:24<00:56,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 43/138 [00:25<00:57,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 44/138 [00:25<00:55,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 45/138 [00:26<00:54,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11659.98 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 46/138 [00:26<00:54,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 47/138 [00:27<00:52,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 48/138 [00:28<00:51,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 49/138 [00:28<00:49,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 50/138 [00:29<00:48,  1.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 51/138 [00:29<00:48,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 52/138 [00:30<00:48,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 53/138 [00:30<00:50,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 54/138 [00:31<00:49,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 55/138 [00:32<00:48,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 56/138 [00:32<00:47,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 57/138 [00:33<00:45,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 58/138 [00:33<00:44,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 59/138 [00:34<00:47,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 60/138 [00:35<00:45,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 61/138 [00:35<00:47,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 62/138 [00:36<00:45,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 63/138 [00:36<00:44,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▋     | 64/138 [00:37<00:43,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 65/138 [00:37<00:42,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 66/138 [00:38<00:40,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▊     | 67/138 [00:39<00:40,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 68/138 [00:39<00:40,  1.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 69/138 [00:40<00:39,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 70/138 [00:40<00:36,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████▏    | 71/138 [00:41<00:36,  1.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 72/138 [00:41<00:36,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 73/138 [00:42<00:36,  1.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 74/138 [00:42<00:35,  1.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 75/138 [00:43<00:35,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 76/138 [00:44<00:37,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 77/138 [00:44<00:36,  1.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 78/138 [00:45<00:37,  1.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 79/138 [00:46<00:35,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 80/138 [00:46<00:37,  1.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▊    | 81/138 [00:47<00:35,  1.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 82/138 [00:48<00:35,  1.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 83/138 [00:48<00:34,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 84/138 [00:49<00:32,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 85/138 [00:49<00:31,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 86/138 [00:50<00:32,  1.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 87/138 [00:51<00:32,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 88/138 [00:51<00:30,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 89/138 [00:52<00:29,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 90/138 [00:52<00:28,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 91/138 [00:53<00:26,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 92/138 [00:53<00:27,  1.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 93/138 [00:54<00:26,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 94/138 [00:55<00:25,  1.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 95/138 [00:55<00:24,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 96/138 [00:56<00:24,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 97/138 [00:56<00:23,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 98/138 [00:57<00:22,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 99/138 [00:58<00:23,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11660.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 100/138 [00:58<00:21,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 101/138 [00:59<00:20,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 102/138 [00:59<00:21,  1.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 103/138 [01:00<00:19,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 104/138 [01:00<00:20,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 105/138 [01:01<00:19,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 106/138 [01:01<00:17,  1.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 107/138 [01:02<00:19,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 108/138 [01:03<00:18,  1.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.48 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 109/138 [01:03<00:17,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 110/138 [01:04<00:17,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 111/138 [01:05<00:16,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 112/138 [01:05<00:16,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 113/138 [01:06<00:15,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 114/138 [01:06<00:14,  1.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 115/138 [01:07<00:14,  1.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 116/138 [01:08<00:13,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 117/138 [01:08<00:12,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 118/138 [01:09<00:11,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 119/138 [01:09<00:11,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 120/138 [01:10<00:10,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 121/138 [01:11<00:10,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 122/138 [01:11<00:09,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 123/138 [01:12<00:09,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 124/138 [01:12<00:08,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 125/138 [01:13<00:07,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 126/138 [01:14<00:06,  1.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 127/138 [01:14<00:06,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 128/138 [01:15<00:05,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 129/138 [01:15<00:05,  1.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 130/138 [01:16<00:04,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 131/138 [01:17<00:04,  1.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 132/138 [01:17<00:03,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 133/138 [01:18<00:02,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 134/138 [01:18<00:02,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 135/138 [01:19<00:01,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▊| 136/138 [01:19<00:01,  1.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 137/138 [01:20<00:00,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 138/138 [01:21<00:00,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAM usage: 11680.49 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SimAOU(FT) score of  data type sst5 is 0.2837 \n",
            " SimAOU(Random) score of  data type sst5 is -0.0000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "a = SimAOU(model,tokenizer,train_dataset, test_dataset, best_seed = 0, num_data_points = 32, data_type = \"sst5\", batch_size_icl = 32, batch_size_zsl = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ef8f7ccb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.2836596573028585, -2.7076809664290994e-06)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a228d4dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# finetune_model_eval(model, tokenizer,train_dataset,test_dataset, best_seed = 50, data_type=\"sst5\", num_data_points = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1053b02",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NanoGPT",
      "language": "python",
      "name": "nanogpt"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
