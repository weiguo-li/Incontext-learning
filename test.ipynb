{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3Zsa50vycAoa",
      "metadata": {
        "id": "3Zsa50vycAoa"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "# sys.path.append(\"./Incontext-learning\") # this part works for goole colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "CM2tO10Z552-",
      "metadata": {
        "id": "CM2tO10Z552-"
      },
      "outputs": [],
      "source": [
        "import utility\n",
        "import metric\n",
        "import importlib\n",
        "importlib.reload(utility)\n",
        "importlib.reload(metric)\n",
        "from utility import (data_selection, evaluate_zeroshot,evaluate_finetuning,evaluate_demonstrations as  evaluate_fewshots, finetune_model_eval)\n",
        "from metric import Rec2FTP, SimAOU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "937daa06",
      "metadata": {
        "id": "937daa06"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Yev1fLLLKSqF",
      "metadata": {
        "id": "Yev1fLLLKSqF"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88f461b",
      "metadata": {
        "id": "d88f461b"
      },
      "source": [
        "# check point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ddf39116",
      "metadata": {
        "id": "ddf39116"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load SST-2 dataset\n",
        "# dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "# load SST-5 dataset\n",
        "dataset = load_dataset(\"SetFit/sst5\")\n",
        "\n",
        "# Load Qwen3 tokenizer and model\n",
        "model_name = \"Qwen/Qwen3-0.6B\"\n",
        "model_path = \"/home/students/wli/UniHeidelberg/semster2/final_projects/models/Qwen3-0.6B-Base\"\n",
        "# model_path = model_name\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, device_map = \"auto\")\n",
        "\n",
        "tokenizer.padding_side = \"left\"\n",
        "# Make sure tokenizer has pad token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# if getattr(model.config.pad_token_id, None) is None:\n",
        "    # pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d659a25c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 8544\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 1101\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 2210\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "VGnN8Sili5wE",
      "metadata": {
        "id": "VGnN8Sili5wE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Sep 20 00:13:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1080 Ti     Off |   00000000:3B:00.0 Off |                  N/A |\n",
            "| 25%   39C    P5             15W /  250W |    1295MiB /  11264MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   1  NVIDIA GeForce GTX 1080 Ti     Off |   00000000:5E:00.0 Off |                  N/A |\n",
            "| 25%   36C    P2             55W /  250W |    1283MiB /  11264MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A    166962      C   ...al-form-attention/.venv/bin/python3       1290MiB |\n",
            "|    1   N/A  N/A    166962      C   ...al-form-attention/.venv/bin/python3       1278MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a3a6126b",
      "metadata": {
        "id": "a3a6126b"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"] # the orginal paper use this\n",
        "test_dataset = dataset[\"validation\"]\n",
        "\n",
        "def add_idx(example, idx):\n",
        "    example[\"idx\"] = idx\n",
        "    return example\n",
        "\n",
        "test_dataset = test_dataset.map(add_idx, with_indices=True)\n",
        "# Format examples as causal LM inputs\n",
        "def preprocess_function(examples):\n",
        "    label_map = {0: \"negative\", 1: \"positive\"}\n",
        "    inputs = [\n",
        "        f\"Sentence: {sentence} Label: {label_map[label]}\"\n",
        "        for sentence, label in zip(examples[\"sentence\"], examples[\"label\"])\n",
        "    ]\n",
        "    # Tokenize with padding/truncation\n",
        "    tokenized = tokenizer(\n",
        "        inputs,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=256,\n",
        "        # return_tensors=\"pt\"\n",
        "        return_tensors=None\n",
        "    )\n",
        "    # Set labels equal to input_ids for causal LM loss\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "def preprocess_function_sst5(examples):\n",
        "    label_map = {0: \"terrible\", 1: \"bad\", 2: \"neutral\", 3: \"good\", 4: \"very great\"}\n",
        "    inputs = [\n",
        "        f\"Sentence: {sentence} Label: {label_map[label]}\"\n",
        "        for sentence, label in zip(examples[\"text\"], examples[\"label\"])\n",
        "    ]\n",
        "    # Tokenize with padding/truncation\n",
        "    tokenized = tokenizer(\n",
        "        inputs,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=256,\n",
        "        # return_tensors=\"pt\"\n",
        "        return_tensors=None\n",
        "    )\n",
        "    # Set labels equal to input_ids for causal LM loss\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "# Tokenize the dataset\n",
        "# tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "train_tokenized_datasets = train_dataset.map(preprocess_function_sst5, batched = True, remove_columns = train_dataset.column_names)\n",
        "test_tokenized_datasets = test_dataset.map(preprocess_function_sst5, batched=True, remove_columns=test_dataset.column_names)\n",
        "# Data collator (handles padding dynamically in batch)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "VfOgObQEcX31",
      "metadata": {
        "id": "VfOgObQEcX31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films. Label: \"\n"
          ]
        }
      ],
      "source": [
        "# test the behavior of LLM before fine tuing\n",
        "prompt = \"Sentence: a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films. Label:\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "# You can control max_length or early stopping\n",
        "output_ids = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=1,    # adjust based on expected label length\n",
        "    do_sample=False,       # greedy decoding\n",
        "    pad_token_id=tokenizer.pad_token_id\n",
        ")\n",
        "\n",
        "# Decode generated tokens\n",
        "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9f0f4688",
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_dataset = test_dataset.select(range(32)) # use a smaller test set for debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b78a38d8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': \"mcconaughey 's fun to watch , the dragons are okay , not much fire in the script .\",\n",
              " 'label': 3,\n",
              " 'label_text': 'positive',\n",
              " 'idx': 254}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset[254]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce1a8d3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|â–‰         | 26/276 [02:00<19:13,  4.61s/it]"
          ]
        }
      ],
      "source": [
        "a = SimAOU(model,tokenizer,train_dataset, test_dataset, best_seed = 0, num_data_points = 32, data_type = \"sst5\", batch_size_icl = 4, batch_size_zsl = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ef8f7ccb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.28639548885282773"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a228d4dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is 0.125\n",
            "Accuracy is 0.28125\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d11123430b9a4f9ebbaa64af949b4c50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:05, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training finished!\n",
            "Accuracy is 0.40625\n",
            " The Rec2FT is 0.1818180165290759\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.1818180165290759"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_model_eval(model, tokenizer,train_dataset,test_dataset, best_seed = 50, data_type=\"sst5\", num_data_points = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lcnhnnvLU_ft",
      "metadata": {
        "id": "lcnhnnvLU_ft"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NanoGPT",
      "language": "python",
      "name": "nanogpt"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
