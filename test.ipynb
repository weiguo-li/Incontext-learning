{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7eeefda3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2fd2d593",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! uv run main.py SimAM_call --data-type \"sst2\" --seed 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3Zsa50vycAoa",
      "metadata": {
        "id": "3Zsa50vycAoa"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import transformers\n",
        "import torch\n",
        "# sys.path.append(\"./Incontext-learning\") # this part works for goole colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "CM2tO10Z552-",
      "metadata": {
        "id": "CM2tO10Z552-"
      },
      "outputs": [],
      "source": [
        "import utility\n",
        "import metric\n",
        "import importlib\n",
        "\n",
        "importlib.reload(utility)\n",
        "importlib.reload(metric)\n",
        "from utility import (\n",
        "    data_selection,\n",
        "    evaluate_zeroshot,\n",
        "    evaluate_finetuning,\n",
        "    evaluate_demonstrations as evaluate_fewshots,\n",
        "    finetune_model_eval,\n",
        "    extract_attn_weights,\n",
        ")\n",
        "from metric import Rec2FTP, SimAOU, SimAM, Kendall\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "937daa06",
      "metadata": {
        "id": "937daa06"
      },
      "outputs": [],
      "source": [
        "# uncomment below if you want to use customized attention module for attention weights extraction before softmax\n",
        "# from transformers.models.qwen3 import modeling_qwen3\n",
        "# from customized_Qwen import Qwen3Attention_v1, AttentionWeightsCollector\n",
        "\n",
        "# modeling_qwen3.Qwen3Attention = Qwen3Attention_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49629fdb",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d88f461b",
      "metadata": {
        "id": "d88f461b"
      },
      "source": [
        "# check point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ddf39116",
      "metadata": {
        "id": "ddf39116"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load SST-2 dataset\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "# load SST-5 dataset\n",
        "# dataset = load_dataset(\"SetFit/sst5\")\n",
        "\n",
        "# Load Qwen3 tokenizer and model\n",
        "model_name = \"Qwen/Qwen3-0.6B\"\n",
        "model_path = \"/home/students/wli/UniHeidelberg/semster2/final_projects/models/Qwen3-0.6B-Base\"\n",
        "# model_path = model_name\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, device_map = \"auto\", attn_implementation=\"eager\")  # Specify eager for attention before softmax\n",
        "\n",
        "tokenizer.padding_side = \"left\"\n",
        "# Make sure tokenizer has pad token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# if getattr(model.config.pad_token_id, None) is None:\n",
        "    # pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a3a6126b",
      "metadata": {
        "id": "a3a6126b"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"] # the orginal paper use this\n",
        "test_dataset = dataset[\"validation\"]\n",
        "\n",
        "def add_idx(example, idx):\n",
        "    example[\"idx\"] = idx\n",
        "    return example\n",
        "\n",
        "test_dataset = test_dataset.map(add_idx, with_indices=True)\n",
        "# Format examples as causal LM inputs\n",
        "def preprocess_function(examples):\n",
        "    label_map = {0: \"negative\", 1: \"positive\"}\n",
        "    inputs = [\n",
        "        f\"Sentence: {sentence} Label: {label_map[label]}\"\n",
        "        for sentence, label in zip(examples[\"sentence\"], examples[\"label\"])\n",
        "    ]\n",
        "    # Tokenize with padding/truncation\n",
        "    tokenized = tokenizer(\n",
        "        inputs,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=256,\n",
        "        # return_tensors=\"pt\"\n",
        "        return_tensors=None\n",
        "    )\n",
        "    # Set labels equal to input_ids for causal LM loss\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "def preprocess_function_sst5(examples):\n",
        "    label_map = {0: \"terrible\", 1: \"bad\", 2: \"neutral\", 3: \"good\", 4: \"very great\"}\n",
        "    inputs = [\n",
        "        f\"Sentence: {sentence} Label: {label_map[label]}\"\n",
        "        for sentence, label in zip(examples[\"text\"], examples[\"label\"])\n",
        "    ]\n",
        "    # Tokenize with padding/truncation\n",
        "    tokenized = tokenizer(\n",
        "        inputs,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=256,\n",
        "        # return_tensors=\"pt\"\n",
        "        return_tensors=None\n",
        "    )\n",
        "    # Set labels equal to input_ids for causal LM loss\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "# Tokenize the dataset\n",
        "# tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "# train_tokenized_datasets = train_dataset.map(preprocess_function_sst5, batched = True, remove_columns = train_dataset.column_names)\n",
        "# test_tokenized_datasets = test_dataset.map(preprocess_function_sst5, batched=True, remove_columns=test_dataset.column_names)\n",
        "# Data collator (handles padding dynamically in batch)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adcbba4b",
      "metadata": {},
      "source": [
        "# test Kendall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b0de6eb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(test_dataset)\n",
        "test_dataset2 = test_dataset.select(range(20))  # for testing purpose, use only 100 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7e830627",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 218/218 [00:11<00:00, 19.11it/s]\n",
            "100%|██████████| 872/872 [08:03<00:00,  1.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kendall's tau of sst2 is 0.1873693018, random baseline is 0.0000711622\n"
          ]
        }
      ],
      "source": [
        "out = Kendall(model, tokenizer,train_dataset,test_dataset, data_type=\"sst2\")  # for testing purpose, use only 100 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3b769f2b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.18296876693546485)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a1e25843",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(out[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3b1b725b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 464])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[3][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9c932309",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([464, 20])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[2][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5757297b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 39, 2048])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[1][0][15].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "17c35cc4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 464, 2048])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[0][0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cd172ec3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# attention_collector = AttentionWeightsCollector(model)\n",
        "# attention_collector.enable_collection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8c49cee8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # import Qwne3ForCausalLM\n",
        "# from transformers import Qwen3ForCausalLM\n",
        "# model = Qwen3ForCausalLM.from_pretrained(model_path, device_map = \"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9b2a1508",
      "metadata": {},
      "outputs": [],
      "source": [
        "# output = extract_attentionweights(\n",
        "#     model, tokenizer, [\"This is a test sentence.\",\" Another test sentence. label: \"], \n",
        "#     batch_size=2, before_softmax=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e0e55228",
      "metadata": {},
      "outputs": [],
      "source": [
        "# output = extract_raw_attention_scores(\n",
        "#     model, tokenizer, [\"This is a test sentence.\",\" Another test sentence. label: \"], \n",
        "#     batch_size=1\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e0d2fe",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "VfOgObQEcX31",
      "metadata": {
        "id": "VfOgObQEcX31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test prompt 2 hello world\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# test the behavior of LLM before fine tuing\n",
        "prompt = \"Sentence: a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films. Label:\"\n",
        "prompts = [\"test prompt how old are \", \"test prompt 2 hello world\"]\n",
        "\n",
        "inputs = tokenizer(prompts, return_tensors=\"pt\").to(model.device)\n",
        "# You can control max_length or early stopping\n",
        "output_ids = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=1,  # adjust based on expected label length\n",
        "    do_sample=False,  # greedy decoding\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "\n",
        "# Decode generated tokens\n",
        "generated_text = tokenizer.decode(output_ids[1], skip_special_tokens=True)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a8a7e11",
      "metadata": {},
      "source": [
        "# test SimAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0addc7f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 28/872 [00:07<03:59,  3.52it/s]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x14689a95db20>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/students/wli/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 796, in _clean_thread_parent_frames\n",
            "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
            "                      ^^^^^^^^^^^^\n",
            "KeyboardInterrupt: \n",
            "  8%|▊         | 70/872 [00:19<03:48,  3.52it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x14689a95db20>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/students/wli/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 781, in _clean_thread_parent_frames\n",
            "    def _clean_thread_parent_frames(\n",
            "\n",
            "KeyboardInterrupt: \n",
            "  9%|▉         | 78/872 [00:22<03:45,  3.53it/s]"
          ]
        }
      ],
      "source": [
        "sim_scores_ft, sim_scores_bf_ft = SimAM(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    best_seed=30,\n",
        "    data_type=\"sst2\",\n",
        "    num_data_points=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3653053f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 20/872 [00:06<04:40,  3.04it/s]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x14ac9cb2dac0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/students/wli/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 781, in _clean_thread_parent_frames\n",
            "    def _clean_thread_parent_frames(\n",
            "\n",
            "KeyboardInterrupt: \n",
            "  7%|▋         | 59/872 [00:19<04:26,  3.04it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x14ac9cb2dac0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/students/wli/UniHeidelberg/semster2/final_projects/incontext_learning/dual-form-attention/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 781, in _clean_thread_parent_frames\n",
            "    def _clean_thread_parent_frames(\n",
            "\n",
            "KeyboardInterrupt: \n",
            "  8%|▊         | 66/872 [00:22<04:24,  3.04it/s]"
          ]
        }
      ],
      "source": [
        "# test_dataset = test_dataset.select(range(20))\n",
        "out = SimAM(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    data_type=\"sst2\",\n",
        "    batch_size_icl=1,\n",
        "    batch_size_zsl=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79f4647",
      "metadata": {},
      "outputs": [],
      "source": [
        "out[0][0][3].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8dcd579",
      "metadata": {},
      "outputs": [],
      "source": [
        "1 + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b3964d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# attention_collector.collect_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c131f30",
      "metadata": {},
      "outputs": [],
      "source": [
        "# a = attention_collector.get_weights_for_layer(4)\n",
        "# b = attention_collector.get_all_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3086e0f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f0c3731",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0f4688",
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_dataset = test_dataset.select(range(32)) # use a smaller test set for debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b78a38d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# for batch in DataLoader(test_dataset, batch_size=2, shuffle=True):\n",
        "#     print(batch)\n",
        "#     print(type(batch))\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f651e2a7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce1a8d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "a = SimAOU(model,tokenizer,train_dataset, test_dataset, best_seed = 0, num_data_points = 32, data_type = \"sst5\", batch_size_icl = 32, batch_size_zsl = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef8f7ccb",
      "metadata": {},
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a228d4dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# finetune_model_eval(model, tokenizer,train_dataset,test_dataset, best_seed = 50, data_type=\"sst5\", num_data_points = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1053b02",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NanoGPT",
      "language": "python",
      "name": "nanogpt"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
